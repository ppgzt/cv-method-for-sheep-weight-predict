{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9d1a8a-6647-44e8-afdd-cb1049f1290a",
   "metadata": {},
   "source": [
    "# A Computer Vision Approach for Predicting Sheep Body Weight in Livestock Farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55fb68-a1d9-46b1-8422-b05483937078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827b793-1e85-4dfd-92c0-966808c6b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = '0'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import requests, glob, shutil\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "def dummy_npwarn_decorator_factory():\n",
    "  def npwarn_decorator(x):\n",
    "    return x\n",
    "  return npwarn_decorator\n",
    "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint, WandbEvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f6b60-4182-4ad2-9253-c4a63f5ab7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# root folder: bego-analysis\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lib import metadata, partitioning, datasets, transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb3d6a-7596-4ded-b302-6dcc7ad49220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping pandas from truncating long strings\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2aa6b-5f12-47d2-8d3e-14bfea99e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders constants\n",
    "data_dir_path = f'{module_path}/data'\n",
    "\n",
    "source_dir_path = f'{data_dir_path}/source'\n",
    "work_dir_path   = f'{data_dir_path}/work'\n",
    "\n",
    "dataset_dir_path   = f'{source_dir_path}/dataset'\n",
    "work_imgs_dir_path = f'{work_dir_path}/images'\n",
    "suited_imgs_path   = f'{work_imgs_dir_path}/suited'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9917d86a-2d96-4fde-b0eb-1831a9bd87c0",
   "metadata": {},
   "source": [
    "# Create Metadata Dataset\n",
    "\n",
    "Load the dataframe with data acquired during the collects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a372a-3436-435d-a848-3164afcbae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v0 = metadata.MetadataProvider(source_dir_path=source_dir_path).load_dataframe()\n",
    "dataset_v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b3f40-d20b-40f1-96d0-ce873fddfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v0.groupby(['collect_id','place']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393172b-5a8d-4986-81d3-516c569c8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v1 = dataset_v0.query('label == 0')\n",
    "dataset_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1032ad1-d65a-4383-b83c-6be307353a2e",
   "metadata": {},
   "source": [
    "## Move suited images do work directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bcf7a-98c5-41ce-855b-496c653cb933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dict = {}\n",
    "\n",
    "file_list = glob.glob(f\"{source_dir_path}/images/**/*DEPTH_320_240_1.png\",recursive=True)\n",
    "for file in file_list:\n",
    "    file_dict[file.split('/')[-1]] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a26513-f4a5-4046-852b-c9d6ecbdc9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_suited_img_to_work_dir(file_name: str, save_dir: str, save_as: str = None):\n",
    "    if save_as is None:\n",
    "        save_as = file_name\n",
    "        \n",
    "    if not os.path.isfile(f'{save_dir}/{file_name}'):\n",
    "        shutil.copyfile(file_dict[file_name], f'{save_dir}/{save_as}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42739f5a-f5d6-4887-890e-a28719b322b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_v1.apply(\n",
    "    lambda row: move_suited_img_to_work_dir(file_name=row['depth'], save_dir=suited_imgs_path), \n",
    "    axis=1\n",
    ")\n",
    "dataset_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51658d-9b4d-4193-b480-94a2ead213c4",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "**PROCESS** \n",
    "\n",
    "Prepare data -> Split data -> Compile the model -> Fit the model -> Predict result from unseen data (test set) -> Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685c7c6-1918-46cb-ae3f-c0a616dd705b",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "*In **run-6** and **run-7**, the code below should be changed to `dataset_exp = dataset_v1.query('place == \"Farm Code\"').iloc[:,:]` changing the Farm Code form **Farm A** or **Farm B*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12ec64ad-e14e-4e26-b6be-29bf3279968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1772, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_exp = dataset_v1.iloc[:,:]\n",
    "dataset_exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f1483-a48f-437b-8947-50a155826ec6",
   "metadata": {},
   "source": [
    "### Dataset Partition\n",
    "\n",
    "Partitioning by TAG (animal identification code), with 85% of the animals for Training and 15% for Testing. In **run-5**, the partitioning strategy used was `partitioning.SplitBySingleFieldLogic()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8996f0-7c3d-415a-9f04-841e452b1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stg  = partitioning.SplitRandomBySingleField()\n",
    "partitions = split_stg.split(\n",
    "    field_name='tag', \n",
    "    dataset=dataset_exp,\n",
    "    train_size=0.85\n",
    ")\n",
    "partitions.groupby('partition').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c9d55-c1e4-4fa2-bdc8-113b840d35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_exp = dataset_exp.merge(partitions, on='tag')\n",
    "dataset_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba36c26-650c-45fb-b1f3-32640818dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = dataset_exp.groupby(\n",
    "    ['partition','place']\n",
    ").size().reset_index(\n",
    "    name='qtd'\n",
    ").to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a00e93-b2bc-4fb9-8093-232e6cbe27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b3ce9-f901-46be-947b-0a0ce7862be2",
   "metadata": {},
   "source": [
    "### Init Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079827b5-5344-44f3-95ea-a9ba077e2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the index value and start a run in wandb (https://wandb.ai/), tracking hyperparameters\n",
    "index = 1\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"collie-x3\",\n",
    "    name=f'run_{index}',\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"train_size\": 0.8,\n",
    "        \"epochs\": (3,200),\n",
    "        \"dense_units\": 128,        \n",
    "        \"split\": split_dict,\n",
    "    }\n",
    ")\n",
    "\n",
    "# [optional] use wandb.config as your config\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecb993-ecf3-4167-b4e7-b1b470e968cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your model prediction visualization callback\n",
    "class WandbClfEvalCallback(WandbEvalCallback):\n",
    "    def __init__(\n",
    "        self, validation_data, data_table_columns, pred_table_columns, num_samples=100\n",
    "    ):\n",
    "        super().__init__(data_table_columns, pred_table_columns)\n",
    "\n",
    "        self.x = validation_data[0]\n",
    "        self.y = validation_data[1]\n",
    "\n",
    "    def add_ground_truth(self, logs=None):\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    This function correspond to the stage Measure metrics and are executed in epochs 50, 100, 150, 165, 180, 190 and 200\n",
    "    \"\"\"\n",
    "    def add_model_predictions(self, epoch, logs=None):\n",
    "        if epoch+1 in [50,100,150,165,180,190,200]:\n",
    "            score = self.model.evaluate(self.x, self.y)\n",
    "            wandb.log({\n",
    "                'test/loss':score[0], \n",
    "                'test/r2_score':score[1],\n",
    "                'test/root_mean_squared_error':score[2],\n",
    "                'test/mean_squared_error':score[3],\n",
    "                'test/mean_absolute_error':score[4],\n",
    "                'test/mean_absolute_percentage_error':score[5],\n",
    "            })\n",
    "            self.model.save(f'output/model_run{index}_epoch{epoch+1}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933ca9b-c463-49ef-9be7-d045f9735229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_exp.to_csv(f'output/dataset{index}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f2189-d3d7-4343-9660-c1a2a56ed594",
   "metadata": {},
   "source": [
    "### Dataset Load and Transformation\n",
    "\n",
    "Load the dataset with the depth images of the animals and apply the transformations to all images. For more information about the behavior of the methods below, see their descriptions in `lib/transformations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154dee6-6ddc-4f5c-ae3c-21b25087e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = datasets.Dataset().load_data(\n",
    "    dataframe = dataset_exp,\n",
    "    img_col_name = 'depth', \n",
    "    img_dir = suited_imgs_path,\n",
    "    truth_col_name = 'weight',\n",
    "    transformations = [\n",
    "        transformations.NoiseRemovalSetMaxValue(max_value=1950),\n",
    "        transformations.AdjustScaleWithFixedMaxValue(max_value=1950),\n",
    "        transformations.Replicate1DtoNDimChannel(dim=3),\n",
    "        transformations.ResizeImageWithPadding(shape=(300,300)),\n",
    "    ],\n",
    "    replicators = []\n",
    ")\n",
    "\n",
    "print('Training:', X_train.shape, Y_train.shape)\n",
    "print(' Testing:', X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8afc2-ac88-44c2-b164-aad6157d6ecd",
   "metadata": {},
   "source": [
    "### Model Compile & Fit\n",
    "\n",
    "- Compiles the model based on EfficientNetV2-B3, with weights trained via imageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0d4b8-3fed-40d6-9ceb-e65932010c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"mean_squared_error\"])\n",
    "    plt.plot(hist.history[\"val_mean_squared_error\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211401d-33e6-4eac-a389-539f65b1a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.R2Score(class_aggregation=\"uniform_average\"),\n",
    "    keras.metrics.RootMeanSquaredError(),\n",
    "    keras.metrics.MeanSquaredError(), \n",
    "    keras.metrics.MeanAbsoluteError(),\n",
    "    keras.metrics.MeanAbsolutePercentageError()\n",
    "] \n",
    "\n",
    "base_model = keras.applications.EfficientNetV2B3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(300,300,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f6b3f-3c37-4dbc-b07a-cac1d8226c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pretrained weights | inference mode\n",
    "base_model.trainable = False\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=(300, 300, 3)),\n",
    "    keras.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(config.dense_units, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebaeed-634d-4d74-9264-5ed196854b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(), \n",
    "    loss = keras.losses.MeanSquaredError(), \n",
    "    metrics = metrics\n",
    ")\n",
    "\n",
    "hist_tl = model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    validation_split=0.15, \n",
    "    epochs=config.epochs[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aedb0b-c054-49a1-9aaa-bb58554ca9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f437604-d436-4e9d-a75b-abfe749c7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary(\n",
    "    show_trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090ab77-f3cd-4187-bd02-d3c345272583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(1e-5), \n",
    "    loss = keras.losses.MeanSquaredError(), \n",
    "    metrics = metrics\n",
    ")\n",
    "\n",
    "hist_ft = model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    validation_split=0.15, \n",
    "    epochs=config.epochs[1],\n",
    "    callbacks=[\n",
    "        WandbMetricsLogger(log_freq='epoch'),\n",
    "        WandbClfEvalCallback(\n",
    "            validation_data=(X_test, Y_test),\n",
    "            data_table_columns=[],\n",
    "            pred_table_columns=[],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eedf6f-a6f4-49dd-9291-d3e45a7273b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fde9a-bd65-453b-88f1-4d103e4b30ad",
   "metadata": {},
   "source": [
    "### Model Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52bb7cb-2ffc-4096-9bdd-1f4b79bb4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose = 0) \n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
